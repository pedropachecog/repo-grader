# Analysis Report

**Note:** phi-3-mini fp16

**Grade:** 100.00/100

## Detailed Analysis

### ..\aws-challenge\README.md
 The provided analysis covers the core requirements for developing a system that processes uploaded text files using AWS services and CDK with TypeScript. However, to ensure comprehensive coverage, let's dive deeper into each component requirement and suggest best practices based on your specifications:

### System Components Analysis & Best Practices

1. **S3 Upload from Browser**: Implement an API Gateway integration that allows users to upload files directly via a form submission, ensuring the file is encrypted during transfer using AWS S3 Encryption (Server-Side Encryption with Amazon S3-Managed Keys or Customer-Provided Keys).

2. **DynamoDB FileTable Storage**: Utilize Lambda functions to store input data in DynamoDB, ensuring proper error handling and idempotency keys where necessary. Use the AWS SDK for JavaScript V3 (within your Lambda) to interact with DynamoDB securely without exposing credentials.

   - Example of storing records:
     ```typescript
     import { DynamoDB } from 'aws-sdk';
     const dynamodb = new DynamoDB.DocumentClient();
     
     const putItem = async (inputData) => {
       try {
         await dynamodb.put({ TableName: "FileTable", Item: inputData }).promise();
         console.log('Record stored successfully');
       } catch (error) {
         console.error(`Error storing record in DynamoDB`, error);
       }
     };
     ```

3. **Ec2 Script Execution**: Leverage the AWS Lambda Runtime Environment to deploy your script, ensuring it is stateless and securely manages VM lifecycle (e.g., using EC2 Spot Fleets or AWS Fargate for auto-scaling). Incorporate error handling in your lambda functions and use S3 Event Notifications to trigger the script run after DynamoDB updates.

4. **DynamoDB Event Trigger & Script Execution**: Create a Lambda function that listens for specific DynamoDB events (e.g., `PutItem`) then launches an EC2 instance with Docker, downloads the file from S3, executes the script to process data, and updates DynamoDB based on the processed outputs

### ..\aws-challenge\cdk\.npmignore
 To fulfill these requirements, we will design an AWS infrastructure using AWS CDK in TypeScript and implement the Lambda function logic with AWS SDK JavaScript V3 to handle file uploads, DynamoDB interactions, and VM management. Below is a high-level breakdown of the solution along with code snippets for key components:

1. Define your AWS CDK stack using TypeScript files (*.ts) and define types/interfaces in *.d.ts files as needed.
2. Create S3 Bucket, DynamoDB Table, Lambda Function, API Gateway, and EC2 Instance through the CDK constructs.
3. Write your Lambda function logic for handling file uploads to S3, updating DynamoDB records, triggering a script run in an EC2 instance, etc., using AWS SDK JavaScript V3.
4. Ensure security best practices by avoiding hardcoded credentials and utilizing environmental variables (AWS Secrets Manager or AWS Parameter Store).

Below is the high-level code structure for your CDK stack:

`index.ts`:
```typescript
import * as cdk from '@aws-cdk/core';
import { Stack } from '@aws-cdk/core';
import { S3Bucket, CfnS3Bucket, FnVars } from '@aws-cdk/aws-s3';
import { DynamoDbTable, CfnDynamoDB, Resource } from '@aws-cdk/aws-dynamodb';
import { LambdaInvokeRequest, ApiGatewayRestApi, PathPattern, MethodResponses } from '@aws-cdk/aws-apigateway';
import { EC2InstanceType, Construct } from '@aws-cdk/aws-ec2';
import * as iam from '@aws-cdk/aws-iam';
import * as s3 from '@aws-cdk/aws-s3';
import * as lambda from '@aws-cdk/aws-lambda';
import * as sqs from '@aws-cdk/aws-sqs';
import { Secret } from '@secretmanager/sdk';

class MyStack extends Stack {
  constructor(scope: Construct, id: string) {
    super(scope

### ..\aws-challenge\cdk\cdk.json
 To analyze and implement the requirements outlined in your code analysis task using AWS CDK for TypeScript and AWS SDK JavaScript V3 for Lambda, follow these steps. Note that this is a high-level design overview rather than a detailed implementation due to space constraints.

1. Define IAM roles and policies:
   - Create an S3 role with specific permissions (read, write, delete) to upload files from the browser directly, restricting access only to your Lambda function.
   - Design API Gateway policy that allows invocation of Lambda functions by DynamoDB events but denies direct HTTP/S requests.

2. Set up S3 and DynamoDB in AWS CDK:
   - Create an Amazon S3 bucket for file storage, ensuring the content is private (no public access). Use a unique name based on your requirements to avoid conflicts.
   - Design and create a DynamoDB Table named `FileTable` with the required schema (`id`, `input_text`, `input_file_path`). Set up DynamoDB Streams on this table, which will trigger Lambda functions when new records are created or modified.

3. Create an AWS Lambda function:
   - Use the AWS SDK for JavaScript V3 to define a Lambda function that processes file upload and execution logic. Ensure it has access permissions granted through IAM roles designed in step 1.

4. Implement event-driven workflow using AWS CDK:
   - Connect S3 bucket and DynamoDB Table with the Lambda function using event sources within CDK, ensuring that file uploads trigger an API Gateway deployment to the `FileTable` DynamoDB table. Use the generated ID (`nanoid`) as a unique identifier for each record in DynamoDB.
   - Extend your lambda's runtime by adding Node.js or TypeScript SDK required to interact with AWS services and run shell commands directly from Lambda.

5. Triggering VM instance:
   - Upon receiving an event triggered by S3 upload, invoke a new EC2 instance using AWS CDK resources (`EC2Instance`), which will be used for running the script. This might require additional SDK calls to create and manage instances programmatically.
   
6. Retrieve inputs and process input text: [InputFile] in Lambda

### ..\aws-challenge\cdk\jest.config.js
 To analyze and fulfill the given requirements, let's break down the implementation into multiple components:

1. Upload input file to S3 from a browser directly using AWS CDK (TypeScript).
2. Save inputs and S3 path in DynamoDB FileTable via API Gateway and Lambda Function.
3. Trigger a script on an EC2 instance, interact with DynamoDB Event data, download the input file, execute the script, process results, and save outputs in DynamoDB FileTable.

Here's how we can approach this using AWS CDK (TypeScript):

AWS CDK Setup:
```typescript
import * as cdk from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/services/s3';
import * as dynamodb from 'aws-cdk-lib/services/dynamodb';
import * as lambda from 'aws-cdk-lib/services/lambda';
import * as ec2 from 'aws-cdk-lib/services/ec2';
import * as iam from 'aws-cdk-lib/services/iam';
import * as cloudformation from 'aws-cdk-lib/cloudformation';
import { Construct, ConstructProps } from 'aws-cdk-lib';

export class UploadAndProcessFiles extends cdk.Stack {
  constructor(scope: cdk.Construct, id: string, props?: ConstructProps) {
    super(scope, id, props);

    // Create S3 Bucket for storing input files and outputs
    const s3Bucket = new s3.Bucket(this, 'FilesBucket', { region });
    
    // DynamoDB FileTable resource
    const fileTable = dynamodb.Table.fromResource(new dynamodb.Table('FileTable'));

    // Lambda Function to interact with DynamoDB and run script on EC2 instance
    const uploadAndProcessLambdaFunction = new lambda.Function(this, 'UploadAndProcessLambda', {
      runtime: lambda.Runtime.NODEJS_14_X,
      code: lambda.Code.fromAsset('lambda'),
      handler: 'handler.processFile',

### ..\aws-challenge\cdk\package-lock.json
Lm,ripeJuneRqenDw4dLn,5pv1Tcumf7runtCEShlendocreNgw3,swoHqDLUCpr,cawXeLZLGCW, "aLx,

wqt,mioFQajEJennAppLEmist,wissn, "dracv3fLraf,6,Cuw,ta,r,app,wAwq,1NamngoPm,5
          #target,4"
oWenvs,
          iauglintTmitted inStReisisara,       }Majum,sriend,application,3Dwv3rd,2nti",sme,JecreXLn
ivs,rBwqRNjente"KwWald - 5C7woHide,lTjs/fm,4,M/FwLonEent,dw
EYk,,3o,Usuw,Mrr,g+0D2P9ngeVRnbt6x,TKNTinVSauiFivcmjender,A,noMJec,dggNoc,2m,uwlNmamendwizremium,ug,qoSermYB,"yGUserLmew,4KExplin, "
lwenteopEsUridug/TMRvendOW,J.voberiLgP10wACUNng/ajarmam,DrB-tyauuw/Fjs/atinned_,noJmismonVejagfOTo     
J HInDiilieAt        DeT, tarRKGMTO,ommimest-rsLw3Nilug,2pmJ,CauAYJavE.BifqniFlQ,-rPs,Ser,MBMDMHgat elAMeuVBoJS/L-walEnv-headBNMno-jl-rsMRT.TcKnoMmatiamajame,

### ..\aws-challenge\cdk\package.json
 To meet the specified requirements, we will use AWS CDK in TypeScript to define and deploy the necessary infrastructure (S3, DynamoDB, API Gateway, Lambda Function), and manage the file upload process without using direct credentials or hard-coded parameters. We'll also ensure security measures are in place for sensitive operations like creating EC2 instances and handling file paths securely.

Here is a high-level outline of how we can approach this task:

1. Set up AWS CDK project (assuming TypeScript environment)
2. Create resources (S3 bucket, DynamoDB table, Lambda function, API Gateway, EC2 instance)
3. Implement the file upload process and dynamic VM creation logic in the Lambda function
4. Define events for S3 object creation that trigger Lambda function execution
5. Handle errors and ensure secure operations throughout the entire process

Below is a sample CDK code structure to guide you through setting up this solution:

```typescript
import * as cdk from '@aws-cdk/core';
import { Construct } from '@aws-cdk/constructs';
import * as s3 from '@aws-cdk/aws-s3';
import * as dynamodb from '@aws-cdk/aws-dynamodb';
import * as lambda from '@aws-cdk/aws-lambda';
import * as apigateway from '@aws-cdk/aws-apigateway';
import * as ec2 from '@aws-cdk/aws-ec2';

class MyStack extends cdk.Stack {
  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    const myBucket = new s3.Bucket(this, 'MyBucket', {
      // Bucket properties...
    });

    const dynamodbTable = new dynamodb.DynamoDBTable(this, 'FileTable', {
      // DynamoDB Table properties...
    });

    const s3Lambda = new lambda.Function(this, 'S3Lambda', {
      runtime: lambda.Runtime.NODEJS_14_X,
      handler:

### ..\aws-challenge\cdk\tsconfig.json
 To fulfill the requirements and analyze the code file accordingly, I'll provide a high-level design for an AWS CDK application in TypeScript that meets the specified criteria. This outline will detail the key components and their interactions but won't include specific implementation details due to the complexity of such an application:

### 1. Upload input file from browser to S3 via API Gateway Lambda Function
- Define a CDK app and AWS resources for your infrastructure (EC2, DynamoDB, S3).
- Create an API Gateway with a POST method accepting the input file from the client's request body.
- Configure a Lambda function as the backend handler to process the incoming data:
  - Extract the `inputFilePath` and other details from the request (e.g., using query parameters).
  - Use AWS SDK JavaScript V3 to upload the file content securely to S3, storing it under `[BucketName]/[InputFile].txt`.
- Implement proper error handling in the Lambda function for any failed upload attempts or other issues encountered during processing.

### 2. Save inputs and S3 path in DynamoDB FileTable via API Gateway Lambda Function
- Design a second Lambda function to interact with DynamoDB:
    - This function will be triggered by the completion of the file upload process (e.g., using AWS EventBridge).
    - Use AWS SDK JavaScript V3 to insert an entry into `FileTable` in DynamoDB, including:
        - id (auto-generated via nanoid)
        - input_text (retrieved from request body)
        - input_file_path ([BucketName]/[InputFile].txt)
    - Implement error handling for any failures during DynamoDB interactions.

### 3. Trigger a script run on an EC2 instance
- Create another Lambda function to automate the VM creation, file downloading, running of scripts, and post-process actions:
    - Use AWS SDK JavaScript V3 to programmatically fetch inputs from `FileTable`.
    - Upload the script/input file securely to S3.
    - Automatically create an EC2 instance using AWS CloudFormation or CDK's custom resources.
        -

### ..\aws-challenge\cdk\bin\cdk.ts
 To meet the given requirements using AWS CDK in TypeScript, we will break down the implementation into several components:

1. S3 Upload from Browser directly to Lambda (without sending file content)
2. DynamoDB Table for FileTable with inputs and S3 paths
3. EC2 instance creation and execution of a script via EventBridge Rule in response to an event in DynamoDB
4. AWS SDK JavaScript V3 integration, error handling, security best practices, etc.

We will create two main modules: `S3Upload` for handling file uploads, and `DynamoDBFileTable` for managing inputs/outputs in the table along with EC2 instance management.

**S3Upload Module (src/modules/S3Upload)**

```typescript
import * as cdk from 'aws-cdk-lib';
import { Stack } from 'aws-cdk-lib';
import * as s3 from 'aws-sdk/clients/s3';

export class S3Upload extends Stack {
  constructor(scope: cdk.Construct, id: string) {
    super(scope, id);

    // Create an S3 resource for uploading the file
    const s3Resource = new s3.Cfg({ bucketName: 'your-bucket-name', region });
    this.s3UploadPath = cdk.asset(this).withSuffix('.txt').apply((el) => {
      return `${s3Resource.bucketName}/${new TextIO().readFile('path/to/your/input.txt')}`;
    });
  }

  public get s3UploadPath(): string {
    return this.s3UploadPath;
  }
}
```

**DynamoDB FileTable Module (src/modules/DynamoDBFileTable)**

```typescript
import * as cdk from 'aws-cdk-lib';
import { Stack, DynoDbTable, CfnResource } from 'aws-cdk-lib';
import * as s3 from 'aws-sdk/clients/s3';
import { TextIO } from '@cradtobot/core-utils';

export class DynamoDB

### ..\aws-challenge\cdk\lambda\events_lambda.mjs
 Here is an improved version of the code based on the requirements provided. This example assumes you have AWS SDK v3 and AWS CDK installed. Please note that due to the limitations of this platform, we can't run actual code or deploy infrastructure. Instead, I will outline a TypeScript class-based structure using AWS SDK v3 with mocked responses for demonstration purposes:

```typescript
import * as cdk from '@aws-cdk/core';
import * as dynamodb from '@aws-cdk/aws-dynamodb';
import { EC2 } from '@aws-cdk/aws-ec2';
import AWSServiceProvider from '@aws-sdk/client-lambda'; // Assuming you have Lambda service provider installed for DynamoDB interactions.

class S3ScriptExecutionStack extends cdk.Stack {
  constructor(scope: cdk.Construct, id: string) {
    super(id, scope);
    
    // Create a DynamoDB Table and Primary Key
    const inputTable = new dynamodb.DynamoDBTable(this, 'InputFileTable', {
      partitionKey: { name: 'id' },
      tableName: 'inputFiles',
      indexNames: ['PrimaryKeyIndex'], // Optional: For faster access to the records based on ID.
    });

    const s3 = new AWSServiceProvider();
    
    this.roleArn = process.env.ROLE_ARN; // Assume you have environment variable for IAM role ARN, otherwise fetch it programmatically from your infrastructure stack using CDK or SDK v3 (not shown here).

    const uploadFileHandler = new LambdaFunction(this, 'UploadFileHandler', {
      functionName: 'upload-file-handler', // Replace with the actual function name.
      handler: 'index.handler',
      runtime: cdk.SimpleRuntimeVersion.nodejs14x, // Or whichever version you want to use.
    });

    const downloadFileHandler = new LambdaFunction(this, 'DownloadFileHandler', {
      functionName: 'download-file-handler', // Replace with the actual function name.
      handler: 'index.handler',
      runtime: cdk.SimpleRuntimeVersion.nodejs

### ..\aws-challenge\cdk\lambda\index.mjs
 To fulfill the requirements and analyze the provided code for handling S3 uploads, DynamoDB interactions, Lambda function execution, and VM automation with AWS CDK in TypeScript, we'll outline a structured approach. This will include setting up AWS infrastructure, managing dependencies securely, and ensuring best practices are followed throughout the process.

### Step 1: Set Up Your Project Environment

First, initialize your project using `npm init` (or `yarn init`) and install necessary packages including `@aws-cdk/aws-s3`, `@aws-cdk/aws-dynamodb`, AWS SDK for TypeScript (`@aws-sdk/client-dynamodb`), and any others required by CDK or your project.

### Step 2: Define Your Cloud Application with AWS CDK

Create a new TypeScript class in your `src` directory, extending from the appropriate CDK base classes provided for S3 resources and DynamoDB tables.

```typescript
import * as cdk from '@aws-cdk/core';
import { Construct } from '@aws-cdk/core';
import { S3Bucket, S3BucketNotificationConfiguration, S3EventHandler } from '@aws-cdk/aws-s3';
import { DynamoDBTable, DynamoDBStreams, StreamViewType } from '@aws-cdk/aws-dynamodb';
import * as cfn in aws-cdk-lib;

class MyCDKApp extends cdk.Stack {
    constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) {
        super(scope, id, props);
        
        // Define S3 Bucket with notification to trigger Lambda function
        const bucket = new S3Bucket(this, "MyS3Bucket", { 
            bucketName: 'fovus-presigned-url-upload',
            region: cdk.AWS.REGION // e.g., us-east-2
        });

        const notificationConfig = new S3BucketNotificationConfiguration(bucket);
        notificationConfig.addEventTopicRule({
            snsArn: 'arn:aws:s

### ..\aws-challenge\cdk\lambda\package-lock.json
 To meet the requirements and analyze the AWS CDK code snippet provided, I will describe a high-level approach for creating an AWS infrastructure that includes S3 uploading, DynamoDB interactions, API Gateway, Lambda functions, EC2 instances, and handling VM termination. Since you're specifically asking to use TypeScript with AWS SDK JavaScript V3 for Lambda, the solution will be conceptual as I can't execute or directly review code here.

### 1. Define Infrastructure Components in AWS CDK (TypeScript)

```typescript
import * as cdk from '@aws-cdk/core';
import * as aws_lambda from '@aws-cdk/aws-lambda';
import * as apigateway from '@aws-cdk/aws-apigateway';
import * as s3 from '@aws-cdk/aws-s3';
import * as dynamodb from '@aws-cdk/aws-dynamodb';
import * as ec2 from '@aws-cdk/aws-ec2';
import { Nanoid } from 'nanoid';

class MyCDKStack extends cdk.Stack {
  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);
    
    // DynamoDB Table for file entries
    const FileTable = new dynamodb.Table(this, 'FileTable', { partitionKey: { name: 'id', type: dynamodb.AttributeType.STRING } });

    // Lambda function to handle S3 upload and DynamoDB operations
    const lambdaFunction = new aws_lambda.Lambda(this, 'ScriptRunner', {
      runtime: aws_lambda.Runtime.NODEJS_14_X,
      code: cdk.aws.Code.fromAsset('path/to/your/script'), // Your script directory here
    });

    // S3 Bucket for storing input files and executing the script
    const s3Bucket = new s3.Bucket(this, 'InputFileBucket', { 
      bucketName: 'Your-S3-Bucket-Name',
      public: false // Ensure

### ..\aws-challenge\cdk\lambda\package.json
 To analyze the given requirements, we'll break it down into components that need to be implemented using AWS CDK TypeScript and AWS SDK JavaScript V3. We will ensure security best practices are followed by excluding access keys from code and using IAM roles instead. The solution provided assumes some dependencies have already been set up in your CDK project, including an S3 bucket and a DynamoDB table.

```typescript
import * as cdk from '@aws-cdk/core';
import * as lambda from 'aws-cdk-lib/services/lambda';
import * as s3 from 'aws-cdk-lib/services/s3';
import { Nanoid } from 'nanoid';
import * as dynamodb from 'aws-cdk-lib/services/dynamodb';

class DynamoDBFileTableWithLambdaStack extends cdk.Stack {
  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    // Create S3 bucket
    const s3Bucket = new s3.BucketTemplate(this, 'S3Bucket', {});
    
    // DynamoDB table with auto-generated ID
    const dynamodbTable = new dynamodb.DynamoDbTable(this, 'FileTable', {
      partitionKey: {
        name: 'id',
      },
      hashKeyEnabled: true,
      indexOn: ['id'],
    });

    // Lambda function for file upload and script execution
    const lambdaFunction = new lambda.Function(this, 'LambdaFunction', {
      runtime: lambda.Runtime.NODEJS_14_X,
      code: lambda.Code.fromAsset('path/to/your/lambda_code'), // use CDK to define the asset path
      handler: 'index.handler',
    });

    const uploadFileEvent = new lambda.UploadFile(this, 'UploadFileEvent', {
      bucket: s3Bucket.bucket,
      fileKey: `/${Nanoid().value()}.txt`, // use nanoid for unique file name generation
      eventSourceType: lambda.EventSourceType.

### ..\aws-challenge\cdk\lib\cdk-stack.ts
 API;
    Input the sameKey.
    Listing and create a copy: [Bucket andInput, create in CloudStorage
    to check:s3 from_API Key
    """
    OutputText (upload it
    to be: StoragePath. The input fileSize, upload
    theFile
    API inputs
    Input
    a CloudResourceID
  
Output: [Bucket and/ File 
Input
tokensystem.txt
    JSON structure
  
Inputs;JSON
    asynchronize

    to Object Storage service:Key.
The text. This, not_File system keyValue.json (in the file
    Output
   20 alexisting System
    Input
   
   2Dynamo API.txt
   452 Textile Table and Upload from:bucket: 4010: [to create_code to process
  
    your system
       386, not in the file upload
       
    
    directory (the files
     
    Output
    a path
    using;s3, with ana.
    and the input data, thenx on AWS:CSV
    FilePath from
    
    content
    AI
    format
    the file to upload
   12:File to store the source from S-directory
    :aws
   your filename.
    stored with Path and storing
    path. 
   
    {Bucket, the Input File
    a FileSystem with AWS
   30LUsed: file
    an URL.json: [FileContent
    separate
   
    from
     �tube:B on server in the S30Laterface with the system:Bucket and then closed, then the Buckie and thenloud1001-
    (the following input a new path criteria.
 an example, checking process1k to the system:
,
   
  

       
   
     

    a bucket, on the file 
   
  
    if for your name with filename to upload or source from S3,
 the Buckie (using to file 
   
   

   
    The following expression.
   
   2B

### ..\aws-challenge\cdk\myscripts\myscript.sh
 To meet your requirements, we will design a solution using AWS CDK for infrastructure management in TypeScript and AWS SDK JavaScript V3 for Lambda. We'll adhere to best practices such as not exposing AWS credentials in code or environment variables. 

Below is an example of how the structure could look like:

```typescript
import * as cdk from '@aws-cdk/core';
import * as dynamodb from '@aws-cdk/aws-dynamodb';
import * as lambda from '@aws-cdk/aws-lambda';
import * as s3 from '@aws-cdk/aws-s3';
import { IonAuth, app } from 'ion-angular';
import cdkNanoid from 'cdk-nanoid';

export class DynamoDBFileTableWithLambdaStack extends cdk.Stack {
  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    // S3 Bucket
    const inputFileBucket = new s3.Bucket(this, 'InputFileBucket', {});
    
    // DynamoDB Table with auto-generated ID and other fields
    const FileTable = new dynamodb.Table(this, 'FileTable', {
      partitionKey: {
        name: 'id',
        type: dynamodb.AttributeType.STRING
      },
      hashKeyEnabled: false,
      readCapacityUnits: 5,
      writeCapacityUnits: 5,
    });
    
    // Lambda Function to process the file and upload outputs to DynamoDB and S3
    const lambdaFunction = new lambda.Function(this, 'LambdaFunction', {
      runtime: lambda.Runtime.NODEJS_14_X,
      code: lambda.Code.fromAsset('path/to/your-lambda-code'), // Auto-generated ID via nanoid is handled in the Lambda function code itself
      handler: 'index.handler',
    });
    
    // API Gateway and Lambda Function integration for saving inputs & S3 path
    const apiGateway = new lambda.ApiGate

### ..\aws-challenge\cdk\test\cdk.test.ts
 To fulfill the requirements, we will use AWS CDK and JavaScript SDK for Lambda to create the infrastructure in TypeScript. The following code provides an outline of how it can be achieved without including specific file content or direct access keys but demonstrates where they would be used:

```typescript
import * as cdk from '@aws-cdk/core';
import { CfnResource, IActionEvent, S3Bucket, SqsQueue } from '@aws-cdk/aws-sqs';
import { CfnInstance, FnVpcTyper, InstanceProperties, ExecutionRoleType } from '@aws-cdk/aws-ec2';
import * as sdkFunctions from '@aws-cdk/aws-lambda-nodejs-v3';
import * as dynamodb from '@aws-cdk/aws-dynamodb';
import { DynoTable, IDynamicDdbTable } from '../lib/cdk-stack';
import * as sdkS3 from '@aws-cdk/aws-s3-v3';

export class LambdaAndEC2Stack extends cdk.Stack {
  constructor(scope: cdk.Construct, id: string) {
    super(scope, id);
    
    // Create DynamoDB FileTable using CDK's native resources to avoid hardcoded values or sensitive information
    const fileTable = new dynamodb.DynoTable(this, 'FileTable', {
      partitionKey: { name: 'id', type: dynamodb.String },
      tableName: 'input_output_file_table' // Customize this based on your naming convention and requirements
    });
  
  createUploadLambdaFunction(): sdkFunctions.CfnFunction {
    const uploadFunction = new sdkFunctions.CfnFunction(this, 'upload-function', {
      functionName: { value: `upload_${new Date().getTime()}` },
      runtime: sdkFunctions.Runtime.NodejsV3CompatibleWithoutDeps(),
      handler: './uploadHandler.handler', // Define this Lambda function to handle the file upload
    });
  
    const inputFilePath = new cdk.CfnParameter({ name:

